{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPN2nm4PlYVt3loNQsUSnEG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nahid0335/ANN-from-scratch-using-numpy/blob/main/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOlINhnnuXu8"
      },
      "source": [
        "# **Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GkQPtaJuMUE"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a0TJtvCu0hb"
      },
      "source": [
        "# **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0b-YgGUukYZ"
      },
      "source": [
        "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "x = (x/255).astype('float32')\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT0ExigE6Ai3"
      },
      "source": [
        "x = x.to_numpy()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TifIxK4rv8_X"
      },
      "source": [
        "class DeepNeuralNetwork():\n",
        "    def __init__(self, sizes, epochs=10, l_rate=0.001):\n",
        "        self.sizes = sizes\n",
        "        self.epochs = epochs\n",
        "        self.l_rate = l_rate\n",
        "        # save all parameters in the neural network in this dictionary\n",
        "        self.params = self.initialization()\n",
        "\n",
        "\n",
        "    def sigmoid(self, x, derivative=False):\n",
        "        if derivative:\n",
        "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "\n",
        "    def softmax(self, x, derivative=False):\n",
        "        exps = np.exp(x - x.max())\n",
        "        if derivative:\n",
        "            return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
        "        return exps / np.sum(exps, axis=0)\n",
        "\n",
        "\n",
        "    def initialization(self):\n",
        "        # number of nodes in each layer\n",
        "        input_layer=self.sizes[0]\n",
        "        hidden_1=self.sizes[1]\n",
        "        hidden_2=self.sizes[2]\n",
        "        output_layer=self.sizes[3]\n",
        "\n",
        "        params = {\n",
        "            'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
        "            'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
        "            'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
        "        }\n",
        "        return params\n",
        "\n",
        "\n",
        "    def forward_pass(self, x_train):\n",
        "        params = self.params\n",
        "\n",
        "        # input layer activations becomes sample\n",
        "        params['A0'] = x_train\n",
        "        #print(params[\"W1\"])\n",
        "        #print(params['A0'])\n",
        "        # input layer to hidden layer 1\n",
        "        params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
        "        params['A1'] = self.sigmoid(params['Z1'])\n",
        "\n",
        "        # hidden layer 1 to hidden layer 2\n",
        "        params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
        "        params['A2'] = self.sigmoid(params['Z2'])\n",
        "\n",
        "        # hidden layer 2 to output layer\n",
        "        params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
        "        params['A3'] = self.softmax(params['Z3'])\n",
        "\n",
        "        return params['A3']\n",
        "\n",
        "\n",
        "    def backward_pass(self, y_train, output):\n",
        "        params = self.params\n",
        "        change_w = {}\n",
        "\n",
        "        # Calculate W3 update\n",
        "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
        "        change_w['W3'] = np.outer(error, params['A2'])\n",
        "\n",
        "        # Calculate W2 update\n",
        "        error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
        "        change_w['W2'] = np.outer(error, params['A1'])\n",
        "\n",
        "        # Calculate W1 update\n",
        "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
        "        change_w['W1'] = np.outer(error, params['A0'])\n",
        "\n",
        "        return change_w\n",
        "\n",
        "\n",
        "    def update_network_parameters(self, changes_to_w):\n",
        "        for key, value in changes_to_w.items():\n",
        "            self.params[key] -= self.l_rate * value\n",
        "\n",
        "\n",
        "    def compute_accuracy(self, x_val, y_val):\n",
        "        predictions = []\n",
        "        for x, y in zip(x_val, y_val):\n",
        "            output = self.forward_pass(x)\n",
        "            pred = np.argmax(output)\n",
        "            predictions.append(pred == np.argmax(y))\n",
        "        \n",
        "        return np.mean(predictions)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, x_train, y_train, x_val, y_val):\n",
        "        start_time = time.time()\n",
        "        for iteration in range(self.epochs):\n",
        "            for x,y in zip(x_train, y_train):\n",
        "                output = self.forward_pass(x)\n",
        "                changes_to_w = self.backward_pass(y, output)\n",
        "                self.update_network_parameters(changes_to_w)\n",
        "            \n",
        "            accuracy = self.compute_accuracy(x_val, y_val)\n",
        "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
        "                iteration+1, time.time() - start_time, accuracy * 100\n",
        "            ))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W94fKO6E0yTc"
      },
      "source": [
        "dnn = DeepNeuralNetwork(sizes=[784, 128, 64, 10],epochs=150,l_rate=0.001)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJjdASXf00X3",
        "outputId": "c836cfa6-d9df-4dff-f060-370f1491ce75"
      },
      "source": [
        "dnn.train(x_train, y_train, x_val, y_val)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Time Spent: 58.03s, Accuracy: 24.50%\n",
            "Epoch: 2, Time Spent: 115.63s, Accuracy: 34.27%\n",
            "Epoch: 3, Time Spent: 172.76s, Accuracy: 37.06%\n",
            "Epoch: 4, Time Spent: 229.60s, Accuracy: 38.14%\n",
            "Epoch: 5, Time Spent: 285.85s, Accuracy: 39.99%\n",
            "Epoch: 6, Time Spent: 342.12s, Accuracy: 42.93%\n",
            "Epoch: 7, Time Spent: 400.10s, Accuracy: 46.42%\n",
            "Epoch: 8, Time Spent: 457.76s, Accuracy: 49.64%\n",
            "Epoch: 9, Time Spent: 514.33s, Accuracy: 52.32%\n",
            "Epoch: 10, Time Spent: 570.65s, Accuracy: 55.19%\n",
            "Epoch: 11, Time Spent: 627.39s, Accuracy: 57.86%\n",
            "Epoch: 12, Time Spent: 685.34s, Accuracy: 60.18%\n",
            "Epoch: 13, Time Spent: 741.76s, Accuracy: 62.20%\n",
            "Epoch: 14, Time Spent: 798.56s, Accuracy: 63.75%\n",
            "Epoch: 15, Time Spent: 855.14s, Accuracy: 64.89%\n",
            "Epoch: 16, Time Spent: 911.16s, Accuracy: 65.99%\n",
            "Epoch: 17, Time Spent: 966.85s, Accuracy: 67.20%\n",
            "Epoch: 18, Time Spent: 1023.63s, Accuracy: 68.09%\n",
            "Epoch: 19, Time Spent: 1079.44s, Accuracy: 68.82%\n",
            "Epoch: 20, Time Spent: 1136.23s, Accuracy: 69.31%\n",
            "Epoch: 21, Time Spent: 1193.73s, Accuracy: 69.73%\n",
            "Epoch: 22, Time Spent: 1250.42s, Accuracy: 70.03%\n",
            "Epoch: 23, Time Spent: 1305.90s, Accuracy: 70.27%\n",
            "Epoch: 24, Time Spent: 1360.85s, Accuracy: 70.47%\n",
            "Epoch: 25, Time Spent: 1417.10s, Accuracy: 70.72%\n",
            "Epoch: 26, Time Spent: 1472.43s, Accuracy: 71.06%\n",
            "Epoch: 27, Time Spent: 1528.55s, Accuracy: 71.28%\n",
            "Epoch: 28, Time Spent: 1584.79s, Accuracy: 71.51%\n",
            "Epoch: 29, Time Spent: 1641.37s, Accuracy: 71.78%\n",
            "Epoch: 30, Time Spent: 1697.93s, Accuracy: 72.07%\n",
            "Epoch: 31, Time Spent: 1754.92s, Accuracy: 72.39%\n",
            "Epoch: 32, Time Spent: 1811.61s, Accuracy: 72.68%\n",
            "Epoch: 33, Time Spent: 1868.45s, Accuracy: 72.85%\n",
            "Epoch: 34, Time Spent: 1925.06s, Accuracy: 73.10%\n",
            "Epoch: 35, Time Spent: 1981.39s, Accuracy: 73.28%\n",
            "Epoch: 36, Time Spent: 2037.89s, Accuracy: 73.74%\n",
            "Epoch: 37, Time Spent: 2094.06s, Accuracy: 74.00%\n",
            "Epoch: 38, Time Spent: 2149.93s, Accuracy: 74.29%\n",
            "Epoch: 39, Time Spent: 2204.60s, Accuracy: 74.55%\n",
            "Epoch: 40, Time Spent: 2259.23s, Accuracy: 74.76%\n",
            "Epoch: 41, Time Spent: 2313.59s, Accuracy: 75.03%\n",
            "Epoch: 42, Time Spent: 2369.27s, Accuracy: 75.28%\n",
            "Epoch: 43, Time Spent: 2426.23s, Accuracy: 75.61%\n",
            "Epoch: 44, Time Spent: 2482.76s, Accuracy: 75.88%\n",
            "Epoch: 45, Time Spent: 2538.13s, Accuracy: 76.14%\n",
            "Epoch: 46, Time Spent: 2593.80s, Accuracy: 76.42%\n",
            "Epoch: 47, Time Spent: 2650.02s, Accuracy: 76.50%\n",
            "Epoch: 48, Time Spent: 2706.12s, Accuracy: 76.79%\n",
            "Epoch: 49, Time Spent: 2762.09s, Accuracy: 76.96%\n",
            "Epoch: 50, Time Spent: 2818.01s, Accuracy: 77.09%\n",
            "Epoch: 51, Time Spent: 2873.98s, Accuracy: 77.18%\n",
            "Epoch: 52, Time Spent: 2930.31s, Accuracy: 77.31%\n",
            "Epoch: 53, Time Spent: 2986.59s, Accuracy: 77.48%\n",
            "Epoch: 54, Time Spent: 3042.38s, Accuracy: 77.53%\n",
            "Epoch: 55, Time Spent: 3098.20s, Accuracy: 77.62%\n",
            "Epoch: 56, Time Spent: 3154.27s, Accuracy: 77.69%\n",
            "Epoch: 57, Time Spent: 3210.33s, Accuracy: 77.58%\n",
            "Epoch: 58, Time Spent: 3266.38s, Accuracy: 77.63%\n",
            "Epoch: 59, Time Spent: 3322.36s, Accuracy: 77.71%\n",
            "Epoch: 60, Time Spent: 3378.99s, Accuracy: 77.86%\n",
            "Epoch: 61, Time Spent: 3435.76s, Accuracy: 77.88%\n",
            "Epoch: 62, Time Spent: 3492.09s, Accuracy: 77.93%\n",
            "Epoch: 63, Time Spent: 3548.37s, Accuracy: 78.12%\n",
            "Epoch: 64, Time Spent: 3604.47s, Accuracy: 78.21%\n",
            "Epoch: 65, Time Spent: 3660.73s, Accuracy: 78.24%\n",
            "Epoch: 66, Time Spent: 3717.43s, Accuracy: 78.28%\n",
            "Epoch: 67, Time Spent: 3774.25s, Accuracy: 78.30%\n",
            "Epoch: 68, Time Spent: 3830.86s, Accuracy: 78.29%\n",
            "Epoch: 69, Time Spent: 3887.61s, Accuracy: 78.32%\n",
            "Epoch: 70, Time Spent: 3944.49s, Accuracy: 78.33%\n",
            "Epoch: 71, Time Spent: 4001.14s, Accuracy: 78.35%\n",
            "Epoch: 72, Time Spent: 4058.06s, Accuracy: 78.50%\n",
            "Epoch: 73, Time Spent: 4115.09s, Accuracy: 78.50%\n",
            "Epoch: 74, Time Spent: 4171.98s, Accuracy: 78.59%\n",
            "Epoch: 75, Time Spent: 4228.28s, Accuracy: 78.70%\n",
            "Epoch: 76, Time Spent: 4284.58s, Accuracy: 78.80%\n",
            "Epoch: 77, Time Spent: 4341.81s, Accuracy: 78.83%\n",
            "Epoch: 78, Time Spent: 4398.81s, Accuracy: 78.89%\n",
            "Epoch: 79, Time Spent: 4454.46s, Accuracy: 78.92%\n",
            "Epoch: 80, Time Spent: 4510.25s, Accuracy: 78.96%\n",
            "Epoch: 81, Time Spent: 4566.29s, Accuracy: 79.01%\n",
            "Epoch: 82, Time Spent: 4622.08s, Accuracy: 79.04%\n",
            "Epoch: 83, Time Spent: 4677.92s, Accuracy: 79.14%\n",
            "Epoch: 84, Time Spent: 4734.02s, Accuracy: 79.20%\n",
            "Epoch: 85, Time Spent: 4789.92s, Accuracy: 79.25%\n",
            "Epoch: 86, Time Spent: 4845.82s, Accuracy: 79.33%\n",
            "Epoch: 87, Time Spent: 4901.90s, Accuracy: 79.39%\n",
            "Epoch: 88, Time Spent: 4958.94s, Accuracy: 79.42%\n",
            "Epoch: 89, Time Spent: 5016.43s, Accuracy: 79.50%\n",
            "Epoch: 90, Time Spent: 5073.92s, Accuracy: 79.60%\n",
            "Epoch: 91, Time Spent: 5131.10s, Accuracy: 79.72%\n",
            "Epoch: 92, Time Spent: 5188.22s, Accuracy: 79.73%\n",
            "Epoch: 93, Time Spent: 5244.90s, Accuracy: 79.81%\n",
            "Epoch: 94, Time Spent: 5301.12s, Accuracy: 79.90%\n",
            "Epoch: 95, Time Spent: 5356.94s, Accuracy: 79.99%\n",
            "Epoch: 96, Time Spent: 5412.44s, Accuracy: 80.11%\n",
            "Epoch: 97, Time Spent: 5468.06s, Accuracy: 80.14%\n",
            "Epoch: 98, Time Spent: 5523.63s, Accuracy: 80.23%\n",
            "Epoch: 99, Time Spent: 5579.72s, Accuracy: 80.27%\n",
            "Epoch: 100, Time Spent: 5635.67s, Accuracy: 80.31%\n",
            "Epoch: 101, Time Spent: 5691.58s, Accuracy: 80.39%\n",
            "Epoch: 102, Time Spent: 5747.64s, Accuracy: 80.46%\n",
            "Epoch: 103, Time Spent: 5804.04s, Accuracy: 80.51%\n",
            "Epoch: 104, Time Spent: 5860.28s, Accuracy: 80.59%\n",
            "Epoch: 105, Time Spent: 5916.01s, Accuracy: 80.67%\n",
            "Epoch: 106, Time Spent: 5971.63s, Accuracy: 80.70%\n",
            "Epoch: 107, Time Spent: 6027.17s, Accuracy: 80.75%\n",
            "Epoch: 108, Time Spent: 6083.22s, Accuracy: 80.85%\n",
            "Epoch: 109, Time Spent: 6139.30s, Accuracy: 80.90%\n",
            "Epoch: 110, Time Spent: 6195.19s, Accuracy: 81.00%\n",
            "Epoch: 111, Time Spent: 6251.08s, Accuracy: 81.08%\n",
            "Epoch: 112, Time Spent: 6306.85s, Accuracy: 81.11%\n",
            "Epoch: 113, Time Spent: 6362.36s, Accuracy: 81.20%\n",
            "Epoch: 114, Time Spent: 6418.23s, Accuracy: 81.26%\n",
            "Epoch: 115, Time Spent: 6474.20s, Accuracy: 81.31%\n",
            "Epoch: 116, Time Spent: 6529.93s, Accuracy: 81.40%\n",
            "Epoch: 117, Time Spent: 6585.98s, Accuracy: 81.44%\n",
            "Epoch: 118, Time Spent: 6641.88s, Accuracy: 81.53%\n",
            "Epoch: 119, Time Spent: 6698.07s, Accuracy: 81.54%\n",
            "Epoch: 120, Time Spent: 6753.94s, Accuracy: 81.55%\n",
            "Epoch: 121, Time Spent: 6810.09s, Accuracy: 81.59%\n",
            "Epoch: 122, Time Spent: 6866.66s, Accuracy: 81.68%\n",
            "Epoch: 123, Time Spent: 6922.49s, Accuracy: 81.68%\n",
            "Epoch: 124, Time Spent: 6978.57s, Accuracy: 81.75%\n",
            "Epoch: 125, Time Spent: 7034.89s, Accuracy: 81.83%\n",
            "Epoch: 126, Time Spent: 7090.93s, Accuracy: 81.88%\n",
            "Epoch: 127, Time Spent: 7146.06s, Accuracy: 81.91%\n",
            "Epoch: 128, Time Spent: 7202.83s, Accuracy: 81.99%\n",
            "Epoch: 129, Time Spent: 7259.42s, Accuracy: 82.04%\n",
            "Epoch: 130, Time Spent: 7315.38s, Accuracy: 82.07%\n",
            "Epoch: 131, Time Spent: 7370.89s, Accuracy: 82.09%\n",
            "Epoch: 132, Time Spent: 7426.83s, Accuracy: 82.11%\n",
            "Epoch: 133, Time Spent: 7483.57s, Accuracy: 82.17%\n",
            "Epoch: 134, Time Spent: 7539.08s, Accuracy: 82.20%\n",
            "Epoch: 135, Time Spent: 7594.62s, Accuracy: 82.53%\n",
            "Epoch: 136, Time Spent: 7650.25s, Accuracy: 83.77%\n",
            "Epoch: 137, Time Spent: 7706.63s, Accuracy: 85.00%\n",
            "Epoch: 138, Time Spent: 7762.28s, Accuracy: 85.98%\n",
            "Epoch: 139, Time Spent: 7818.03s, Accuracy: 86.70%\n",
            "Epoch: 140, Time Spent: 7873.79s, Accuracy: 87.30%\n",
            "Epoch: 141, Time Spent: 7929.82s, Accuracy: 87.76%\n",
            "Epoch: 142, Time Spent: 7985.27s, Accuracy: 88.16%\n",
            "Epoch: 143, Time Spent: 8040.99s, Accuracy: 88.57%\n",
            "Epoch: 144, Time Spent: 8096.47s, Accuracy: 88.81%\n",
            "Epoch: 145, Time Spent: 8152.18s, Accuracy: 89.03%\n",
            "Epoch: 146, Time Spent: 8208.02s, Accuracy: 89.11%\n",
            "Epoch: 147, Time Spent: 8262.98s, Accuracy: 89.25%\n",
            "Epoch: 148, Time Spent: 8318.81s, Accuracy: 89.35%\n",
            "Epoch: 149, Time Spent: 8374.55s, Accuracy: 89.42%\n",
            "Epoch: 150, Time Spent: 8430.79s, Accuracy: 89.50%\n"
          ]
        }
      ]
    }
  ]
}